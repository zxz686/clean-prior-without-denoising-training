{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.measure import compare_psnr\n",
    "# check whether run in Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('Running in Colab.')\n",
    "    !pip3 install timm==0.4.5  # 0.3.2 does not work in Colab\n",
    "    !git clone https://github.com/facebookresearch/mae.git\n",
    "    sys.path.append('./mae')\n",
    "else:\n",
    "    sys.path.append('..')\n",
    "import models_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_one_image_average(img,img_ori, model, iterations=50):\n",
    "    # ImageNet mean and std used for normalization\n",
    "    imagenet_mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    imagenet_std = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to('cuda')\n",
    "    \n",
    "    # Prepare the original image for visualization\n",
    "    original_img = torch.tensor(img)\n",
    "    original_img = torch.clip((original_img * imagenet_std + imagenet_mean) * 255, 0, 255).int()\n",
    "\n",
    "    # Initialize a tensor to accumulate the reconstructions on GPU\n",
    "    # 确保accumulated_recons是浮点型\n",
    "    accumulated_recons = torch.zeros_like(torch.tensor(img).unsqueeze(dim=0)).to('cuda').float()\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        x = torch.tensor(img).to('cuda')\n",
    "        x = x.unsqueeze(dim=0)\n",
    "        x = torch.einsum('nhwc->nchw', x)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, y, _ = model(x.float(), mask_ratio=0.5)\n",
    "            y = model.unpatchify(y)\n",
    "            y = torch.einsum('nchw->nhwc', y)\n",
    "\n",
    "            # 累加浮点型重建结果\n",
    "            accumulated_recons += y.float()\n",
    "\n",
    "    # Calculate the average reconstruction and move it back to CPU\n",
    "    avg_reconstruction = (accumulated_recons / iterations).detach().cpu()\n",
    "\n",
    "    # 在可视化之前将平均重建结果转换为整型\n",
    "    avg_reconstruction = torch.clip((avg_reconstruction * imagenet_std + imagenet_mean) * 255, 0, 255).int()\n",
    "\n",
    "\n",
    "    # Set up the plot\n",
    "    plt.rcParams['figure.figsize'] = [24, 24]\n",
    "\n",
    "    # Plotting the original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original_img.numpy())\n",
    "    plt.title(\"Original Image\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plotting the average reconstruction image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(avg_reconstruction[0].numpy())\n",
    "    plt.title(\"Average Reconstruction\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    print(np.shape(avg_reconstruction[0].numpy()))\n",
    "    print(np.shape(img))\n",
    "    #print(avg_reconstruction[0].numpy()/255.)\n",
    "    print(img)\n",
    "    original_img_ori = torch.tensor(img_ori)\n",
    "    original_img_ori = torch.clip((original_img_ori * imagenet_std + imagenet_mean) * 255, 0, 255).int()\n",
    "    print(np.shape(original_img))\n",
    "    psrn_noisy = compare_psnr(avg_reconstruction[0].numpy()/255.,original_img.numpy()/255.)\n",
    "    psnr_gt = compare_psnr(avg_reconstruction[0].numpy()/255.,original_img_ori.numpy()/255.)\n",
    "    print ('PSNR_noisy: %f   PSRN_gt: %f ' % (psrn_noisy, psnr_gt), '\\r', end='')\n",
    "    #ssim = \n",
    "    #print(psnr)\n",
    "    #print(\"SSIM=\"+ssim)\n",
    "\n",
    "# define the utils\n",
    "\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def show_image(image, title=''):\n",
    "    # image is [H, W, 3]\n",
    "    assert image.shape[2] == 3\n",
    "    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int())\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.axis('off')\n",
    "    return\n",
    "\n",
    "def prepare_model(chkpt_dir, arch='mae_vit_large_patch16'):\n",
    "    # build model\n",
    "    model = getattr(models_mae, arch)()\n",
    "    # load model\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
    "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    print(msg)\n",
    "    return model\n",
    "\n",
    "def run_one_image(img, model):\n",
    "    x = torch.tensor(img)\n",
    "\n",
    "    # make it a batch-like\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    x = torch.einsum('nhwc->nchw', x)\n",
    "\n",
    "    # run MAE\n",
    "    loss, y, mask = model(x.float(), mask_ratio=0.75)\n",
    "    y = model.unpatchify(y)\n",
    "    y = torch.einsum('nchw->nhwc', y).detach().cpu()\n",
    "\n",
    "    # visualize the mask\n",
    "    mask = mask.detach()\n",
    "    mask = mask.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2 *3)  # (N, H*W, p*p*3)\n",
    "    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping\n",
    "    mask = torch.einsum('nchw->nhwc', mask).detach().cpu()\n",
    "    \n",
    "    x = torch.einsum('nchw->nhwc', x)\n",
    "\n",
    "    # masked image\n",
    "    im_masked = x * (1 - mask)\n",
    "\n",
    "    # MAE reconstruction pasted with visible patches\n",
    "    im_paste = x * (1 - mask) + y * mask\n",
    "\n",
    "    # make the plt figure larger\n",
    "    plt.rcParams['figure.figsize'] = [24, 24]\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    show_image(x[0], \"original\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    show_image(im_masked[0], \"masked\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    show_image(y[0], \"reconstruction\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    show_image(im_paste[0], \"reconstruction + visible\")\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE_Self2Self_like(img, model, iterations=50):\n",
    "    # ImageNet mean and std used for normalization\n",
    "    imagenet_mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    imagenet_std = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to('cuda')\n",
    "    \n",
    "    # Prepare the original image for visualization\n",
    "    original_img = torch.tensor(img)\n",
    "    original_img = torch.clip((original_img * imagenet_std + imagenet_mean) * 255, 0, 255).int()\n",
    "\n",
    "    # Initialize a tensor to accumulate the reconstructions on GPU\n",
    "    # 确保accumulated_recons是浮点型\n",
    "    accumulated_recons = torch.zeros_like(torch.tensor(img).unsqueeze(dim=0)).to('cuda').float()\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        x = torch.tensor(img).to('cuda')\n",
    "        x = x.unsqueeze(dim=0)\n",
    "        x = torch.einsum('nhwc->nchw', x)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, y, _ = model(x.float(), mask_ratio=0.5)\n",
    "            y = model.unpatchify(y)\n",
    "            y = torch.einsum('nchw->nhwc', y)\n",
    "\n",
    "            # 累加浮点型重建结果\n",
    "            accumulated_recons += y.float()\n",
    "\n",
    "    # Calculate the average reconstruction and move it back to CPU\n",
    "    avg_reconstruction = (accumulated_recons / iterations).detach().cpu()\n",
    "\n",
    "    # 在可视化之前将平均重建结果转换为整型\n",
    "    avg_reconstruction = torch.clip((avg_reconstruction * imagenet_std + imagenet_mean) * 255, 0, 255).int()\n",
    "    '''\n",
    "    # Set up the plot\n",
    "    plt.rcParams['figure.figsize'] = [24, 24]\n",
    "\n",
    "    # Plotting the original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original_img.numpy())\n",
    "    plt.title(\"Original Image\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plotting the average reconstruction image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(avg_reconstruction[0].numpy())\n",
    "    plt.title(\"Average Reconstruction\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    print(np.shape(avg_reconstruction[0].numpy()))\n",
    "    print(np.shape(img))\n",
    "    #print(avg_reconstruction[0].numpy()/255.)\n",
    "    print(img)\n",
    "    original_img_ori = torch.tensor(img_ori)\n",
    "    original_img_ori = torch.clip((original_img_ori * imagenet_std + imagenet_mean) * 255, 0, 255).int()\n",
    "    print(np.shape(original_img))\n",
    "    psrn_noisy = compare_psnr(avg_reconstruction[0].numpy()/255.,original_img.numpy()/255.)\n",
    "    psnr_gt = compare_psnr(avg_reconstruction[0].numpy()/255.,original_img_ori.numpy()/255.)\n",
    "    print ('PSNR_noisy: %f   PSRN_gt: %f ' % (psrn_noisy, psnr_gt), '\\r', end='')\n",
    "    #ssim = \n",
    "    #print(psnr)\n",
    "    #print(\"SSIM=\"+ssim)\n",
    "    '''\n",
    "    output_img = avg_reconstruction[0].numpy()\n",
    "    return output_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘mae_visualize_vit_large.pth’ already there; not retrieving.\n",
      "\n",
      "<All keys matched successfully>\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# download checkpoint if not exist\n",
    "!wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large.pth\n",
    "\n",
    "chkpt_dir = 'mae_visualize_vit_large.pth'\n",
    "model_mae = prepare_model(chkpt_dir, 'mae_vit_large_patch16')\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndef batch_process_images_with_model(input_folder, output_folder, model, iterations=50):\\n    if not os.path.exists(output_folder):\\n        os.makedirs(output_folder)\\n\\n    # 获取所有有效图片文件\\n    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith((\\'.png\\', \\'.jpg\\', \\'.jpeg\\', \\'.gif\\', \\'.bmp\\'))]\\n\\n    # 使用tqdm创建进度条\\n    for image_name in tqdm(image_files, desc=\"Processing images\"):\\n        input_image_path = os.path.join(input_folder, image_name)\\n        output_image_path = os.path.join(output_folder, image_name)\\n        process_image_with_model(input_image_path, output_image_path, model, iterations)\\n        # 已移除打印文件名，进度条将显示进度\\n \\ndef batch_process_images_with_model(input_folder, output_folder, model, iterations=50):\\n    if not os.path.exists(output_folder):\\n        os.makedirs(output_folder)\\n\\n    # 使用tqdm创建进度条\\n    for image_name in tqdm(os.listdir(input_folder), desc=\"Processing images\"):\\n        if image_name.lower().endswith((\\'.png\\', \\'.jpg\\', \\'.jpeg\\', \\'.gif\\', \\'.bmp\\')):\\n            input_image_path = os.path.join(input_folder, image_name)\\n            output_image_path = os.path.join(output_folder, image_name)\\n            process_image_with_model(input_image_path, output_image_path, model, iterations)\\n            print(f\\'Processed image {image_name}\\')\\n        # 已移除打印文件名，进度条将显示进度\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def process_image_with_model(input_image_path, output_image_path, model, iterations=50):\n",
    "    img = Image.open(input_image_path)\n",
    "    img = np.array(img) / 255.\n",
    "    assert img.shape == (224, 224, 3)\n",
    "    # normalize by ImageNet mean and std\n",
    "    img = img - imagenet_mean\n",
    "    img = img / imagenet_std\n",
    "    processed_img = MAE_Self2Self_like(img, model, iterations)\n",
    "    # 将数组的数据类型转换为 np.uint8\n",
    "    processed_img = processed_img.astype(np.uint8)\n",
    "    processed_img_pil = Image.fromarray(processed_img)\n",
    "    processed_img_pil.save(output_image_path)\n",
    "\n",
    "\n",
    "def batch_process_images_with_model(input_folder, output_folder, model, iterations=50):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for image_name in os.listdir(input_folder):\n",
    "        if image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "            input_image_path = os.path.join(input_folder, image_name)\n",
    "            output_image_path = os.path.join(output_folder, image_name)\n",
    "            # 检查输出文件夹中是否已存在该图片\n",
    "            if not os.path.exists(output_image_path):\n",
    "                process_image_with_model(input_image_path, output_image_path, model, iterations)\n",
    "            #process_image_with_model(input_image_path, output_image_path, model, iterations)\n",
    "            #print(f'Processed image {image_name}')\n",
    "'''\n",
    "\n",
    "def batch_process_images_with_model(input_folder, output_folder, model, iterations=50):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 获取所有有效图片文件\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "    # 使用tqdm创建进度条\n",
    "    for image_name in tqdm(image_files, desc=\"Processing images\"):\n",
    "        input_image_path = os.path.join(input_folder, image_name)\n",
    "        output_image_path = os.path.join(output_folder, image_name)\n",
    "        process_image_with_model(input_image_path, output_image_path, model, iterations)\n",
    "        # 已移除打印文件名，进度条将显示进度\n",
    "'''''' \n",
    "def batch_process_images_with_model(input_folder, output_folder, model, iterations=50):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 使用tqdm创建进度条\n",
    "    for image_name in tqdm(os.listdir(input_folder), desc=\"Processing images\"):\n",
    "        if image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "            input_image_path = os.path.join(input_folder, image_name)\n",
    "            output_image_path = os.path.join(output_folder, image_name)\n",
    "            process_image_with_model(input_image_path, output_image_path, model, iterations)\n",
    "            print(f'Processed image {image_name}')\n",
    "        # 已移除打印文件名，进度条将显示进度\n",
    "''' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘mae_visualize_vit_large_ganloss.pth’ already there; not retrieving.\n",
      "\n",
      "<All keys matched successfully>\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 示例使用\n",
    "input_folder = 'CBSD68-224-Poisson-lam/lam40'  # 修改为您的输入文件夹路径\n",
    "output_folder = 'CBSD68-224-Poisson-lam-mae/lam40'  # 修改为您的输出文件夹路径\n",
    "# This is an MAE model trained with an extra GAN loss for more realistic generation (ViT-Large, training mask ratio=0.75)\n",
    "\n",
    "# download checkpoint if not exist\n",
    "!wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_large_ganloss.pth\n",
    "\n",
    "chkpt_dir = 'mae_visualize_vit_large_ganloss.pth'\n",
    "model_mae_gan = prepare_model('mae_visualize_vit_large_ganloss.pth', 'mae_vit_large_patch16')\n",
    "print('Model loaded.')\n",
    "\n",
    "batch_process_images_with_model(input_folder, output_folder, model_mae_gan, iterations=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
